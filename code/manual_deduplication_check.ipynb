{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_multiple_notes = pd.read_csv('/Users/lifuchen/Desktop/OpenNotes/data/multiple_note.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>seq_num</th>\n",
       "      <th>icd_code</th>\n",
       "      <th>icd_version</th>\n",
       "      <th>diagnosis_category</th>\n",
       "      <th>gender</th>\n",
       "      <th>anchor_age</th>\n",
       "      <th>anchor_year</th>\n",
       "      <th>anchor_year_group</th>\n",
       "      <th>...</th>\n",
       "      <th>days_since_anchor</th>\n",
       "      <th>cleaned_note_text</th>\n",
       "      <th>text_kept_exact_sentence_match</th>\n",
       "      <th>text_kept_exact_ngram_match</th>\n",
       "      <th>text_kept_levenshtein_match</th>\n",
       "      <th>similarity_scores_levenshtein_match</th>\n",
       "      <th>text_kept_sentence_transformer_match</th>\n",
       "      <th>similarity_scores_sentence_transformer_match</th>\n",
       "      <th>text_kept_lcs_match</th>\n",
       "      <th>similarity_scores_lcs_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10070024</td>\n",
       "      <td>26769931</td>\n",
       "      <td>1</td>\n",
       "      <td>F323</td>\n",
       "      <td>10</td>\n",
       "      <td>Major Depression</td>\n",
       "      <td>F</td>\n",
       "      <td>23</td>\n",
       "      <td>2142</td>\n",
       "      <td>2014 - 2016</td>\n",
       "      <td>...</td>\n",
       "      <td>1124</td>\n",
       "      <td>\\nName:  ___                   Unit No:   ___...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10070024</td>\n",
       "      <td>26398294</td>\n",
       "      <td>1</td>\n",
       "      <td>F3189</td>\n",
       "      <td>10</td>\n",
       "      <td>Bipolar Disorder</td>\n",
       "      <td>F</td>\n",
       "      <td>23</td>\n",
       "      <td>2142</td>\n",
       "      <td>2014 - 2016</td>\n",
       "      <td>...</td>\n",
       "      <td>1135</td>\n",
       "      <td>Chief Complaint:\\n\"I made a mistake. \"\\n \\nMaj...</td>\n",
       "      <td>['chief complaint: \"i made a mistake.', '\" maj...</td>\n",
       "      <td>['no: ___', 'chief complaint: \"i made a mistak...</td>\n",
       "      <td>['chief complaint: \"i made a mistake.', '\" maj...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.54154727...</td>\n",
       "      <td>['chief complaint: \"i made a mistake.', '\" maj...</td>\n",
       "      <td>[1.0, 1.0000001192092896, 1.0000001192092896, ...</td>\n",
       "      <td>['chief complaint: \"i made a mistake.', '\" maj...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.37735849...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10080985</td>\n",
       "      <td>24679803</td>\n",
       "      <td>1</td>\n",
       "      <td>F332</td>\n",
       "      <td>10</td>\n",
       "      <td>Major Depression</td>\n",
       "      <td>F</td>\n",
       "      <td>22</td>\n",
       "      <td>2179</td>\n",
       "      <td>2014 - 2016</td>\n",
       "      <td>...</td>\n",
       "      <td>132</td>\n",
       "      <td>\\nName:  ___                   Unit No:   ___...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10080985</td>\n",
       "      <td>26523165</td>\n",
       "      <td>1</td>\n",
       "      <td>F329</td>\n",
       "      <td>10</td>\n",
       "      <td>Major Depression</td>\n",
       "      <td>F</td>\n",
       "      <td>22</td>\n",
       "      <td>2179</td>\n",
       "      <td>2014 - 2016</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>Chief Complaint:\\ngenetic predisposition to br...</td>\n",
       "      <td>['sex: f service: emergency allergies: amoxici...</td>\n",
       "      <td>['no: ___', 'patient herself denies any signif...</td>\n",
       "      <td>['chief complaint: genetic predisposition to b...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 0.8837209302325582, ...</td>\n",
       "      <td>['chief complaint: genetic predisposition to b...</td>\n",
       "      <td>[1.0000001192092896, 1.0, 1.0, 1.0, 1.0, 0.932...</td>\n",
       "      <td>['chief complaint: genetic predisposition to b...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 0.875, 0.30555555555...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10266157</td>\n",
       "      <td>29245849</td>\n",
       "      <td>1</td>\n",
       "      <td>F332</td>\n",
       "      <td>10</td>\n",
       "      <td>Major Depression</td>\n",
       "      <td>F</td>\n",
       "      <td>76</td>\n",
       "      <td>2194</td>\n",
       "      <td>2011 - 2013</td>\n",
       "      <td>...</td>\n",
       "      <td>1755</td>\n",
       "      <td>\\nName:  ___                  Unit No:   ___\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id  seq_num icd_code  icd_version diagnosis_category  \\\n",
       "0    10070024  26769931        1     F323           10   Major Depression   \n",
       "1    10070024  26398294        1    F3189           10   Bipolar Disorder   \n",
       "2    10080985  24679803        1     F332           10   Major Depression   \n",
       "3    10080985  26523165        1     F329           10   Major Depression   \n",
       "4    10266157  29245849        1     F332           10   Major Depression   \n",
       "\n",
       "  gender  anchor_age  anchor_year anchor_year_group  ... days_since_anchor  \\\n",
       "0      F          23         2142       2014 - 2016  ...              1124   \n",
       "1      F          23         2142       2014 - 2016  ...              1135   \n",
       "2      F          22         2179       2014 - 2016  ...               132   \n",
       "3      F          22         2179       2014 - 2016  ...               130   \n",
       "4      F          76         2194       2011 - 2013  ...              1755   \n",
       "\n",
       "                                   cleaned_note_text  \\\n",
       "0   \\nName:  ___                   Unit No:   ___...   \n",
       "1  Chief Complaint:\\n\"I made a mistake. \"\\n \\nMaj...   \n",
       "2   \\nName:  ___                   Unit No:   ___...   \n",
       "3  Chief Complaint:\\ngenetic predisposition to br...   \n",
       "4   \\nName:  ___                  Unit No:   ___\\...   \n",
       "\n",
       "                      text_kept_exact_sentence_match  \\\n",
       "0                                                NaN   \n",
       "1  ['chief complaint: \"i made a mistake.', '\" maj...   \n",
       "2                                                NaN   \n",
       "3  ['sex: f service: emergency allergies: amoxici...   \n",
       "4                                                NaN   \n",
       "\n",
       "                         text_kept_exact_ngram_match  \\\n",
       "0                                                NaN   \n",
       "1  ['no: ___', 'chief complaint: \"i made a mistak...   \n",
       "2                                                NaN   \n",
       "3  ['no: ___', 'patient herself denies any signif...   \n",
       "4                                                NaN   \n",
       "\n",
       "                         text_kept_levenshtein_match  \\\n",
       "0                                                NaN   \n",
       "1  ['chief complaint: \"i made a mistake.', '\" maj...   \n",
       "2                                                NaN   \n",
       "3  ['chief complaint: genetic predisposition to b...   \n",
       "4                                                NaN   \n",
       "\n",
       "                 similarity_scores_levenshtein_match  \\\n",
       "0                                                NaN   \n",
       "1  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.54154727...   \n",
       "2                                                NaN   \n",
       "3  [1.0, 1.0, 1.0, 1.0, 1.0, 0.8837209302325582, ...   \n",
       "4                                                NaN   \n",
       "\n",
       "                text_kept_sentence_transformer_match  \\\n",
       "0                                                NaN   \n",
       "1  ['chief complaint: \"i made a mistake.', '\" maj...   \n",
       "2                                                NaN   \n",
       "3  ['chief complaint: genetic predisposition to b...   \n",
       "4                                                NaN   \n",
       "\n",
       "        similarity_scores_sentence_transformer_match  \\\n",
       "0                                                NaN   \n",
       "1  [1.0, 1.0000001192092896, 1.0000001192092896, ...   \n",
       "2                                                NaN   \n",
       "3  [1.0000001192092896, 1.0, 1.0, 1.0, 1.0, 0.932...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                 text_kept_lcs_match  \\\n",
       "0                                                NaN   \n",
       "1  ['chief complaint: \"i made a mistake.', '\" maj...   \n",
       "2                                                NaN   \n",
       "3  ['chief complaint: genetic predisposition to b...   \n",
       "4                                                NaN   \n",
       "\n",
       "                         similarity_scores_lcs_match  \n",
       "0                                                NaN  \n",
       "1  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.37735849...  \n",
       "2                                                NaN  \n",
       "3  [1.0, 1.0, 1.0, 1.0, 1.0, 0.875, 0.30555555555...  \n",
       "4                                                NaN  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_multiple_notes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load English tokenizer, tagger, parser and NER\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    doc = nlp(text)\n",
    "    return [\n",
    "        \" \".join(sent.text.lower().split())  # lowercase + strip extra internal spaces\n",
    "        for sent in doc.sents\n",
    "        if sent.text.strip()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_removed_sentences_colored(original_text, kept_sentences_by_method):\n",
    "    original_sentences = split_into_sentences(original_text)\n",
    "\n",
    "    # Track each sentence instance separately\n",
    "    sentence_status = {i: {\"sent\": sent, \"removed_by\": []} for i, sent in enumerate(original_sentences)}\n",
    "\n",
    "    for method, kept in kept_sentences_by_method.items():\n",
    "        kept_set = set(kept)\n",
    "        for i, sent in enumerate(original_sentences):\n",
    "            if sent not in kept_set:\n",
    "                sentence_status[i][\"removed_by\"].append(method)\n",
    "\n",
    "    # Generate HTML\n",
    "    html_output = []\n",
    "    for i in range(len(original_sentences)):\n",
    "        sent = sentence_status[i][\"sent\"]\n",
    "        removed_by = sentence_status[i][\"removed_by\"]\n",
    "\n",
    "        if not removed_by:\n",
    "            html_output.append(f\"<p>{sent}</p>\")\n",
    "        else:\n",
    "            color = method_colors.get(removed_by[0], \"gray\")\n",
    "            method_list = \", \".join(sorted(set(removed_by)))\n",
    "            html_output.append(\n",
    "                f\"<p><span style='color:{color}; text-decoration:line-through;' title='Removed by {method_list}'>\"\n",
    "                f\"{sent}</span> <em style='color:{color}'>(removed by {method_list})</em></p>\"\n",
    "            )\n",
    "\n",
    "    return \"\\n\".join(html_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# Attempt to parse the kept_sentences if they are stringified\n",
    "def parse_kept_sentences(x):\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    elif isinstance(x, str): # actually the case\n",
    "        try:\n",
    "            return ast.literal_eval(x)\n",
    "        except:\n",
    "            return []\n",
    "    return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved to deduplication_colored_2.html\n"
     ]
    }
   ],
   "source": [
    "methods_to_check = {\n",
    "    \"Exact Match\": \"text_kept_exact_sentence_match\",\n",
    "    \"Ngram\": \"text_kept_exact_ngram_match\",\n",
    "    \"Levenshtein\": \"text_kept_levenshtein_match\",\n",
    "    \"Sentence Transformer\": \"text_kept_sentence_transformer_match\",\n",
    "    \"LCS\": \"text_kept_lcs_match\"\n",
    "}\n",
    "\n",
    "method_colors = {\n",
    "    \"Exact Sentence Match\": \"grey\",\n",
    "    \"Ngram\": \"orange\",\n",
    "    \"Levenshtein\": \"purple\",\n",
    "    \"Sentence Transformer\": \"blue\",\n",
    "    \"LCS\": \"green\"\n",
    "}\n",
    "\n",
    "row_idx = 3  # change to any row you want to inspect\n",
    "row = df_multiple_notes.iloc[row_idx]\n",
    "original_text = row[\"text\"]\n",
    "\n",
    "# Gather kept sentences for each method\n",
    "kept_sentences_by_method = {\n",
    "    method: parse_kept_sentences(row.get(col))\n",
    "    for method, col in methods_to_check.items()\n",
    "}\n",
    "\n",
    "# Generate and save HTML\n",
    "combined_html = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"utf-8\">\n",
    "    <title>Deduplication Comparison</title>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Combined Highlighting of Removed Sentences (Color-Coded by Method)</h1>\n",
    "    <ul>\n",
    "        {''.join([f\"<li style='color:{color}'>{method}</li>\" for method, color in method_colors.items()])}\n",
    "    </ul>\n",
    "    {highlight_removed_sentences_colored(original_text, kept_sentences_by_method)}\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "with open(\"/Users/lifuchen/Desktop/deduplication_colored_2.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(combined_html)\n",
    "\n",
    "print(\"✅ Saved to deduplication_colored_2.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3', '.', 'substance', 'use', 'disorders', ':', '#', ')']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"3. substance use disorders: #)\"\n",
    "tokens = [token.text for token in nlp(sentence)]\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved to deduplication_colored_no_ngram_2.html\n"
     ]
    }
   ],
   "source": [
    "methods_to_check = {\n",
    "    \"Exact Match\": \"text_kept_exact_sentence_match\",\n",
    "    #\"Ngram\": \"text_kept_exact_ngram_match\",\n",
    "    \"Levenshtein\": \"text_kept_levenshtein_match\",\n",
    "    \"Sentence Transformer\": \"text_kept_sentence_transformer_match\",\n",
    "    \"LCS\": \"text_kept_lcs_match\"\n",
    "}\n",
    "\n",
    "method_colors = {\n",
    "    \"Exact Sentence Match\": \"grey\",\n",
    "    #\"Ngram\": \"orange\",\n",
    "    \"Levenshtein\": \"purple\",\n",
    "    \"Sentence Transformer\": \"blue\",\n",
    "    \"LCS\": \"green\"\n",
    "}\n",
    "\n",
    "row_idx = 3  # change to any row you want to inspect\n",
    "row = df_multiple_notes.iloc[row_idx]\n",
    "original_text = row[\"text\"]\n",
    "\n",
    "# Gather kept sentences for each method\n",
    "kept_sentences_by_method = {\n",
    "    method: parse_kept_sentences(row.get(col))\n",
    "    for method, col in methods_to_check.items()\n",
    "}\n",
    "\n",
    "# Generate and save HTML\n",
    "combined_html = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"utf-8\">\n",
    "    <title>Deduplication Comparison</title>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Combined Highlighting of Removed Sentences (Color-Coded by Method)</h1>\n",
    "    <ul>\n",
    "        {''.join([f\"<li style='color:{color}'>{method}</li>\" for method, color in method_colors.items()])}\n",
    "    </ul>\n",
    "    {highlight_removed_sentences_colored(original_text, kept_sentences_by_method)}\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "with open(\"/Users/lifuchen/Desktop/deduplication_colored_no_ngram_2.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(combined_html)\n",
    "\n",
    "print(\"✅ Saved to deduplication_colored_no_ngram_2.html\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BMI706",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
